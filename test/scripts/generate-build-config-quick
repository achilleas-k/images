#!/usr/bin/env python3
#
# Generate a JSON file that lists the test configurations that should be run in GitLab along with the reason for each.
import fnmatch
import hashlib
import json
import os
import shutil
from contextlib import contextmanager
from tempfile import NamedTemporaryFile, TemporaryDirectory

import imgtestlib as testlib

PUSH_CONTAINER = "./tools/ci/push-container.sh"

ARCHITECTURES = ["x86_64", "aarch64"]
MANIFEST_ONLY_ARCHES = ["ppc64le", "s390x"]


def make_ci_job(distro, arch, image_type, config_name, config_path):
    build_name = testlib.gen_build_name(distro, arch, image_type, config_name)
    image_path = f"./build/{build_name}"
    return {
        f"build/{distro}/{arch}/{image_type}/{config_name}": {
            "stage": "test",
            "script": [
                "sudo ./test/scripts/setup-osbuild-repo",
                "sudo ./test/scripts/install-dependencies",
                f"./test/scripts/build-image {distro} {image_type} {config_path}"
                f"./test/scripts/boot-image {distro} {arch} {image_type} '{image_path}'"
                f"./test/scripts/upload-results {distro} {arch} {image_type} {config_path}"
            ],
            "extends": ".terraform",
            "variables": {
                "RUNNER": f"aws/fedora-39-{arch}",
                "INTERNAL_NETWORK": "rhel" in distro,
            }
        }
    }


def read_config_map():
    with open(testlib.CONFIG_MAP, "r", encoding="utf-8") as config_map_file:
        return json.load(config_map_file)


def matches(name: str, filters: list[str]) -> bool:
    return any(fnmatch.fnmatch(name, i) for i in filters)


def expand_config_map():
    """
    Expand config map creating a single config for each config-distro-arch-imagetype combination in a tree as:

        <distro>/<arch>/<image-type>/<config-name>.json

    and return the path to a config map that lists these.
    """
    images = testlib.list_images()
    map_dir = os.path.dirname(testlib.CONFIG_MAP)
    expanded_map = {}
    for config_path, filters in read_config_map().items():
        for image in images:
            distro = image["distro"]
            arch = image["arch"]
            image_type = image["image-type"]
            if image_type not in filters["image-types"]:
                continue
            # filter on distro and arch
            distro_filters = filters.get("distros", [])
            if distro_filters and distro and not matches(distro, distro_filters):
                continue
            arch_filters = filters.get("arches", [])
            if arch_filters and arch and not matches(arch, arch_filters):
                continue

            # paths in config map are relative to the map's directory
            config_fname = os.path.basename(config_path)
            real_config_path = os.path.join(map_dir, config_path)

            dai_path = os.path.join("test/configs/expanded", distro, arch, image_type)
            os.makedirs(dai_path, exist_ok=True)

            # make paths absolute so it's easier to work with
            new_config_path = os.path.abspath(os.path.join(dai_path, config_fname))
            shutil.copyfile(real_config_path, new_config_path)
            expanded_map[new_config_path] = {
                "distros": [distro],
                "arches": [arch],
                "image-types": [image_type],
            }

    expanded_map_path = "expanded-config-map.json"
    with open(expanded_map_path, mode="w", encoding="utf-8") as expmap_fp:
        json.dump(expanded_map, expmap_fp, indent=2)

    return expanded_map_path, expanded_map


def generate_manifests(outputdir):
    """
    Generate all manifest using the default config map but with no content and return a dictionary mapping each manifest
    file to the manifest data and its ID.

    Before generating manifests, the config-map is expanded, which means that for each distro-arch-imagetype-config
    combination, a separate configuration file is created. This expanded tree is used to add unique ostree source
    options to configurations with dependencies, such as ostree disk images and installers.  The modified configurations
    are used in a second pass of the manifest generation so that configurations with dependencies are also considered
    modified when a dependency changes.
    """
    expanded_map_path, expanded_map = expand_config_map()
    print("🗒️ Generating no-content manifests using the expanded config map")
    err = testlib.gen_manifests(outputdir, packages=False, containers=False, commits=False, metadata=True,
                                config_map=expanded_map_path)

    stderr = err.decode().splitlines()
    for line in stderr:
        print(line)

    # Modify the URL in osbuild dependencies to add the hash of the manifest that an ostree image depends on and
    # regenerate the manifests. This lets us know if ostree-dependent manifests, like edge-ami, need to be rebuilt when
    # the image definition doesn't change but its dependency, edge-container, does.
    print("🔄 Adding dependency manifest ID to ostree URL")
    for config_path, filters in expanded_map.items():
        # paths are absolute
        with open(config_path, encoding="utf-8") as config_fp:
            config = json.load(config_fp)
        if not (depends := config.get("depends")):
            continue

        dep_config_name = depends["config"]
        dep_image_type = depends["image-type"]

        distro = filters["distros"][0]
        arch = filters["arches"][0]

        dep_manifest_path = os.path.join(outputdir,
                                         testlib.gen_build_name(distro, arch, dep_image_type, dep_config_name))
        with open(dep_manifest_path, encoding="utf-8") as dep_manifest_fp:
            checksum = hashlib.sha256(dep_manifest_fp.read().encode()).hexdigest()

        config["ostree"]["url"] += "/" + checksum
        with open(config_path, mode="w", encoding="utf-8") as config_fp:
            json.dump(config, config_fp)

    print("🗒️ Generating no-content manifests using the expanded config map (with modified ostree URLs)")
    err = testlib.gen_manifests(outputdir, packages=False, containers=False, commits=False, metadata=True,
                                config_map=expanded_map_path)

    print("✅ Manifest generation done!\n")
    return testlib.read_manifests(outputdir, compute_ids=False)


def invert_dict(md):
    """
    Invert a k->v dictionary into v->k.
    """
    new = {}
    for k, v in md.items():
        new[str(v)] = k
    print("inverted")
    print(f"{len(md)} -> {len(new)}")
    return new


def manifest_dict_diff(a, b):
    """
    Given two manifest dictionaries mapping filename->manifest, return three sets of filenames:
    Modified: manifest filenames that differ in content between a and b.
    Added: manifest filenames that appear in b but not a.
    Removed: manifest filenames that appear in a but not b.

    The function assumes that the mappings are one-to-one. Files with identical content will be removed in the process.
    The metadata for manifests is ignored. Only the manifests themselves are used in the content comparison.
    """
    # extract manifest from each item
    a_man = {k: v["data"]["manifest"] for k, v in a.items()}
    b_man = {k: v["data"]["manifest"] for k, v in b.items()}

    # invert the dictionaries so we can address them by content
    a_inv = invert_dict(a_man)
    b_inv = invert_dict(b_man)

    # manifests in a that aren't in b
    removed = set(a_inv) - set(b_inv)
    removed_names = set(a_inv[v] for v in removed)

    # manifests in b that aren't in a
    added = set(b_inv) - set(a_inv)
    added_names = set(b_inv[v] for v in added)

    # names that appear in both added and removed are modified
    modified_names = added_names & removed_names

    # removed modified names from the added and removed sets
    added_names -= modified_names
    removed_names -= modified_names

    return modified_names, added_names, removed_names


@contextmanager
def git_worktree_ctx(commit):
    """
    Git worktree and working directory context manager.

    Creates a worktree from a commit, changes the working directory into it, and cleans up on exit, reverting the
    working directory and removing the worktree.
    """
    cur_dir = os.getcwd()
    with TemporaryDirectory() as worktree_dir:
        print(f"Creating worktree for {commit} at {worktree_dir}")
        testlib.runcmd_nc(["git", "worktree", "add", worktree_dir, commit])
        os.chdir(worktree_dir)
        try:
            yield
        finally:
            os.chdir(cur_dir)
            # force remove since we'll have changes in the worktree
            testlib.runcmd_nc(["git", "worktree", "remove", "--force", worktree_dir])


def generate_gitlab_ci(configs):
    pass


def main():
    testlib.check_config_names()

    with TemporaryDirectory() as manifest_dir:
        # Generate head manifests without content
        manifests_pr = generate_manifests(os.path.join(manifest_dir, "head"))

        # Find the merge-base with origin/main to generate manifests and check for changes
        merge_base, _ = testlib.runcmd(["git", "merge-base", "origin/main", "HEAD"])
        merge_base = merge_base.decode().strip()
        # Use a worktree in the temporary directory so we don't affect the PR head working directory
        with git_worktree_ctx(merge_base):
            manifests_main = generate_manifests(os.path.join(manifest_dir, "merge-base"))

    modified_names, added_names, removed_names = manifest_dict_diff(manifests_main, manifests_pr)

    # collect configurations for new builds
    new_builds = []

    print(f"{len(modified_names)} modified")
    for idx, name in enumerate(modified_names):
        print(f"{idx:4d}: {name}")
        br = manifests_pr[name]["data"]["build-request"]
        new_builds.append({
            "distro": br["distro"],
            "arch": br["arch"],
            "image-type": br["image-type"],
            "config": br["config"]["name"],
        })

    print(f"{len(removed_names)} removed")
    for idx, name in enumerate(removed_names):
        print(f"{idx:4d}: {name}")

    print(f"{len(added_names)} added")
    for idx, name in enumerate(added_names):
        print(f"{idx:4d}: {name}")
        br = manifests_pr[name]["data"]["build-request"]
        new_builds.append({
            "distro": br["distro"],
            "arch": br["arch"],
            "image-type": br["image-type"],
            "config": br["config"]["name"],
        })

    # write configs and push them to S3 using the current commit ID as filename for gitlab CI to read
    with NamedTemporaryFile(mode="w") as build_configs_file:
        json.dump(new_builds, build_configs_file)
        build_configs_file.flush()
        testlib.upload_build_config(build_configs_file.name)


if __name__ == "__main__":
    main()
